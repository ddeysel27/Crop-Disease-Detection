{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149878cc",
   "metadata": {},
   "source": [
    "# Species classifier on PlantVillage, Cassava, Rice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8d5e8",
   "metadata": {},
   "source": [
    "### create a single species dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2325104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "BASE = \"/content/processed\"\n",
    "OUTPUT = f\"{BASE}/species\"\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) PLANTVILLAGE â†’ extract species from folder namess\n",
    "# ------------------------------------------------------------\n",
    "def collect_plantvillage(path):\n",
    "    print(\"Processing PlantVillage...\")\n",
    "\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        split_dir = f\"{path}/{split}\"\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "\n",
    "        for class_folder in os.listdir(split_dir):\n",
    "            full = os.path.join(split_dir, class_folder)\n",
    "            if not os.path.isdir(full):\n",
    "                continue\n",
    "\n",
    "            # Extract species name (before the three underscores)\n",
    "            species = class_folder.split(\"___\")[0]\n",
    "            species_dir = os.path.join(OUTPUT, species)\n",
    "            ensure_dir(species_dir)\n",
    "\n",
    "            # Copy images\n",
    "            for img in os.listdir(full):\n",
    "                src = os.path.join(full, img)\n",
    "                dst = os.path.join(species_dir, img)\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) SINGLE-SPECIES DATASETS (Cassava, Rice)\n",
    "# ------------------------------------------------------------\n",
    "def collect_single_species_with_diseases(path, species):\n",
    "    print(f\"Processing {species}...\")\n",
    "\n",
    "    species_dir = os.path.join(OUTPUT, species)\n",
    "    ensure_dir(species_dir)\n",
    "\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        split_dir = os.path.join(path, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            continue\n",
    "\n",
    "        # Each subfolder is a disease class, but species is always the same\n",
    "        for disease_folder in os.listdir(split_dir):\n",
    "            full = os.path.join(split_dir, disease_folder)\n",
    "            if not os.path.isdir(full):\n",
    "                continue\n",
    "\n",
    "            for img in os.listdir(full):\n",
    "                src = os.path.join(full, img)\n",
    "                dst = os.path.join(species_dir, img)\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) RUN\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "collect_plantvillage(f\"{BASE}/plantVillage\")\n",
    "collect_single_species_with_diseases(f\"{BASE}/cassava\", \"Cassava\")\n",
    "collect_single_species_with_diseases(f\"{BASE}/riceleaf\", \"Rice\")\n",
    "\n",
    "print(\"Unified species dataset created at:\", OUTPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ab3cf",
   "metadata": {},
   "source": [
    "### Create species_split\n",
    "  - train\n",
    "  - val\n",
    "  - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd06f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random\n",
    "\n",
    "SOURCE = \"/content/processed/species\"\n",
    "OUTPUT = \"/content/processed/species_split\"\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(OUTPUT, split), exist_ok=True)\n",
    "\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "print(\"Splitting species into train/val/test...\")\n",
    "\n",
    "for species in os.listdir(SOURCE):\n",
    "    sp_dir = os.path.join(SOURCE, species)\n",
    "    if not os.path.isdir(sp_dir):\n",
    "        continue\n",
    "\n",
    "    images = os.listdir(sp_dir)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n = len(images)\n",
    "    n_train = int(train_ratio * n)\n",
    "    n_val = int(val_ratio * n)\n",
    "\n",
    "    train_imgs = images[:n_train]\n",
    "    val_imgs   = images[n_train:n_train+n_val]\n",
    "    test_imgs  = images[n_train+n_val:]\n",
    "\n",
    "    # create species folders\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        ensure_dir(os.path.join(OUTPUT, split, species))\n",
    "\n",
    "    # copy images\n",
    "    for img in train_imgs:\n",
    "        shutil.copy(os.path.join(sp_dir, img),\n",
    "                    os.path.join(OUTPUT, \"train\", species, img))\n",
    "\n",
    "    for img in val_imgs:\n",
    "        shutil.copy(os.path.join(sp_dir, img),\n",
    "                    os.path.join(OUTPUT, \"val\", species, img))\n",
    "\n",
    "    for img in test_imgs:\n",
    "        shutil.copy(os.path.join(sp_dir, img),\n",
    "                    os.path.join(OUTPUT, \"test\", species, img))\n",
    "\n",
    "print(\"Done! Split dataset created at:\", OUTPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed7c55",
   "metadata": {},
   "source": [
    "### Species Classifier (ViT) - Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Train ViT Species Classifier (Correct Final Version)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = \"/content/processed/species_split\"\n",
    "MODEL_NAME = \"species_classifier_vit.pth\"\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "EPOCHS = 12\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Transforms\n",
    "# ------------------------------\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_tfms = val_tfms\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Datasets\n",
    "# ------------------------------\n",
    "train_ds = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"),   transform=val_tfms)\n",
    "test_ds  = datasets.ImageFolder(os.path.join(DATA_DIR, \"test\"),  transform=test_tfms)\n",
    "\n",
    "NUM_CLASSES = len(train_ds.classes)\n",
    "print(\"Detected species:\", train_ds.classes)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# DataLoaders\n",
    "# ------------------------------\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dl  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# ViT Model\n",
    "# ------------------------------\n",
    "model = models.vit_b_16(weights=\"IMAGENET1K_V1\")\n",
    "model.heads.head = nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Training Loop\n",
    "# ------------------------------\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_dl:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            preds = model(imgs).argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={total_loss/len(train_dl):.4f} | Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Final Test Accuracy\n",
    "# ------------------------------\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_dl:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        preds = model(imgs).argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(\"Test Accuracy:\", correct / total * 100, \"%\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Save model\n",
    "# ------------------------------\n",
    "torch.save(model.state_dict(), MODEL_NAME)\n",
    "print(\"Saved:\", MODEL_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
