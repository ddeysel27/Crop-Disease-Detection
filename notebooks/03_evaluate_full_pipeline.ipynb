{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05671902",
   "metadata": {},
   "source": [
    "# 03 — Evaluate & Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports & basic setup\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# If you want to use your src/ modules:\n",
    "import sys\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import MODELS_DIR, DATA_PROCESSED_DIR, DEVICE\n",
    "from src.models.loaders import (\n",
    "    load_yolo_seg_model,\n",
    "    load_vit_model,\n",
    ")\n",
    "from src.pipeline.inference import (\n",
    "    apply_mask_and_crop,\n",
    "    run_pipeline,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6cd057",
   "metadata": {},
   "source": [
    "### Define transform and label mappings\n",
    "Update the SPECIES_LABELS and disease label mappings to match how you trained your models (folder names / class order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ffad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: transforms & label mappings\n",
    "\n",
    "# Standard ViT / ImageNet transforms (adjust if you used something different)\n",
    "IMG_SIZE = 224\n",
    "\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# ---- LABEL MAPPINGS ----\n",
    "# These must match the class order you used in training\n",
    "\n",
    "# Example mapping for species classifier:\n",
    "SPECIES_LABELS = [\n",
    "    \"cassava\",\n",
    "    \"rice\",\n",
    "    \"plantvillage\"  # <-- e.g. generic bucket for PlantVillage dataset\n",
    "    # add/remove depending on what you actually trained\n",
    "]\n",
    "\n",
    "SPECIES_IDX2NAME = {i: name for i, name in enumerate(SPECIES_LABELS)}\n",
    "\n",
    "# Example disease label mappings per model\n",
    "# These should match the folders in each dataset's 'train'/'val' set\n",
    "CASSAVA_LABELS = [\n",
    "    \"cassava_bacterial_blight\",\n",
    "    \"cassava_brown_streak\",\n",
    "    \"cassava_green_mottle\",\n",
    "    \"cassava_healthy\",\n",
    "]\n",
    "\n",
    "RICE_LABELS = [\n",
    "    \"rice_bacterial_leaf_blight\",\n",
    "    \"rice_brown_spot\",\n",
    "    \"rice_leaf_smut\",\n",
    "]\n",
    "\n",
    "PLANTVILLAGE_LABELS = [\n",
    "    # TODO: fill this with your actual PlantVillage class names in order\n",
    "    \"tomato_bacterial_spot\",\n",
    "    \"tomato_early_blight\",\n",
    "    \"tomato_healthy\",\n",
    "    # ...\n",
    "]\n",
    "\n",
    "DISEASE_LABEL_MAP = {\n",
    "    \"cassava\": CASSAVA_LABELS,\n",
    "    \"rice\": RICE_LABELS,\n",
    "    \"plantvillage\": PLANTVILLAGE_LABELS,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e876ce97",
   "metadata": {},
   "source": [
    "# Load all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e735511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: load models\n",
    "\n",
    "yolo = load_yolo_seg_model(MODELS_DIR / \"yolo_plantdoc_seg.pt\").to(DEVICE)\n",
    "\n",
    "species_model = load_vit_model(MODELS_DIR / \"species_classifier_vit.pth\").to(DEVICE)\n",
    "cassava_model = load_vit_model(MODELS_DIR / \"cassava_best.pth\").to(DEVICE)\n",
    "rice_model    = load_vit_model(MODELS_DIR / \"rice_leaf_best.pth\").to(DEVICE)\n",
    "plantv_model  = load_vit_model(MODELS_DIR / \"plant_village_best.pth\").to(DEVICE)\n",
    "\n",
    "species_model.eval()\n",
    "cassava_model.eval()\n",
    "rice_model.eval()\n",
    "plantv_model.eval()\n",
    "\n",
    "disease_models = {\n",
    "    \"cassava\": cassava_model,\n",
    "    \"rice\": rice_model,\n",
    "    \"plantvillage\": plantv_model,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd25b0",
   "metadata": {},
   "source": [
    "### Generic evaluation dataset\n",
    "This dataset will just walk through an image folder and use the folder name as the ground-truth label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67de8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: generic dataset for evaluation\n",
    "\n",
    "class FolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects folder structure:\n",
    "        root/\n",
    "            class_1/\n",
    "                img1.jpg\n",
    "                ...\n",
    "            class_2/\n",
    "                ...\n",
    "    \"\"\"\n",
    "    def __init__(self, root: Path, transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.samples: List[Tuple[Path, str]] = []\n",
    "        for class_dir in sorted(self.root.iterdir()):\n",
    "            if not class_dir.is_dir():\n",
    "                continue\n",
    "            label = class_dir.name\n",
    "            for img_path in class_dir.rglob(\"*\"):\n",
    "                if img_path.suffix.lower() in {\".jpg\", \".jpeg\", \".png\"}:\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "        self.class_names = sorted({label for _, label in self.samples})\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img)\n",
    "        else:\n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "\n",
    "        return img_tensor, label, str(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ff689b",
   "metadata": {},
   "source": [
    "### Wrapper to run full pipeline on a PIL image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c73e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: pipeline wrapper for notebook use\n",
    "\n",
    "def predict_species(img_tensor: torch.Tensor, model: torch.nn.Module) -> str:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(DEVICE)  # [1, C, H, W]\n",
    "        logits = model(img_tensor)\n",
    "        pred_idx = torch.argmax(logits, dim=1).item()\n",
    "    return SPECIES_IDX2NAME[pred_idx]\n",
    "\n",
    "def predict_disease(\n",
    "    img_tensor: torch.Tensor,\n",
    "    model: torch.nn.Module,\n",
    "    species_name: str,\n",
    ") -> str:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img_tensor = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "        logits = model(img_tensor)\n",
    "        pred_idx = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    labels = DISEASE_LABEL_MAP[species_name]\n",
    "    return labels[pred_idx]\n",
    "\n",
    "def run_full_pipeline_on_path(\n",
    "    img_path: Path,\n",
    ") -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Returns (species_pred, disease_pred)\n",
    "    \"\"\"\n",
    "    # 1) read image\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # 2) YOLO segmentation -> mask + crop\n",
    "    #    We use the helper from src.pipeline.inference\n",
    "    leaf = apply_mask_and_crop(yolo, img_np)\n",
    "\n",
    "    # 3) convert cropped leaf to tensor\n",
    "    leaf_pil = Image.fromarray(leaf)\n",
    "    leaf_tensor = eval_tfms(leaf_pil)\n",
    "\n",
    "    # 4) Species prediction\n",
    "    species_pred = predict_species(leaf_tensor, species_model)\n",
    "\n",
    "    # 5) Disease model according to species\n",
    "    if species_pred not in disease_models:\n",
    "        raise ValueError(f\"No disease model configured for species '{species_pred}'\")\n",
    "\n",
    "    disease_model = disease_models[species_pred]\n",
    "    disease_pred = predict_disease(leaf_tensor, disease_model, species_pred)\n",
    "\n",
    "    return species_pred, disease_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b519d2",
   "metadata": {},
   "source": [
    "### Evaluation loop for one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: evaluation loop for one dataset\n",
    "\n",
    "def evaluate_dataset(\n",
    "    dataset_root: Path,\n",
    "    assumed_species: str,\n",
    "    batch_size: int = 1,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    dataset_root: e.g. data/processed/cassava/val\n",
    "    assumed_species: the ground-truth species of this dataset,\n",
    "                     so we know how to compare labels.\n",
    "\n",
    "    Returns a dict with accuracy and metrics.\n",
    "    \"\"\"\n",
    "    ds = FolderDataset(dataset_root, transform=None)  # we handle tfms inside pipeline\n",
    "\n",
    "    y_true: List[str] = []\n",
    "    y_pred: List[str] = []\n",
    "    img_paths: List[str] = []\n",
    "\n",
    "    for _, label, path_str in tqdm(ds, desc=f\"Evaluating {dataset_root.name}\"):\n",
    "        img_path = Path(path_str)\n",
    "\n",
    "        try:\n",
    "            species_pred, disease_pred = run_full_pipeline_on_path(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # optional: check whether pipeline species matches assumed dataset species\n",
    "        if species_pred != assumed_species:\n",
    "            # you can log this separately if you want species accuracy too\n",
    "            pass\n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(disease_pred)\n",
    "        img_paths.append(str(img_path))\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cls_report = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=sorted(set(y_true + y_pred)))\n",
    "\n",
    "    return {\n",
    "        \"dataset_root\": str(dataset_root),\n",
    "        \"assumed_species\": assumed_species,\n",
    "        \"accuracy\": acc,\n",
    "        \"classification_report\": cls_report,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"labels\": sorted(set(y_true + y_pred)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694e583",
   "metadata": {},
   "source": [
    "### Run evaluations for all datasets and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: run evaluation for all processed datasets you want\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Example paths – change to match your actual processed layout\n",
    "cassava_val_dir = DATA_PROCESSED_DIR / \"cassava\" / \"val\"\n",
    "rice_val_dir    = DATA_PROCESSED_DIR / \"riceleaf\" / \"val\"\n",
    "plantv_val_dir  = DATA_PROCESSED_DIR / \"plantVillage\" / \"val\"\n",
    "\n",
    "if cassava_val_dir.exists():\n",
    "    results[\"cassava\"] = evaluate_dataset(cassava_val_dir, assumed_species=\"cassava\")\n",
    "\n",
    "if rice_val_dir.exists():\n",
    "    results[\"rice\"] = evaluate_dataset(rice_val_dir, assumed_species=\"rice\")\n",
    "\n",
    "if plantv_val_dir.exists():\n",
    "    results[\"plantvillage\"] = evaluate_dataset(plantv_val_dir, assumed_species=\"plantvillage\")\n",
    "\n",
    "print(\"Summary accuracy:\")\n",
    "for name, r in results.items():\n",
    "    print(f\"{name}: {r['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d08bd",
   "metadata": {},
   "source": [
    "### Inspect one classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae03ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: inspect report for one dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ds_name = \"cassava\"  # change to \"rice\" / \"plantvillage\" etc\n",
    "report = results[ds_name][\"classification_report\"]\n",
    "\n",
    "df_report = pd.DataFrame(report).T\n",
    "df_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324bc5f",
   "metadata": {},
   "source": [
    "### Save metrics to JSON for powerpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: save results to experiments/ folder\n",
    "\n",
    "EXPERIMENTS_DIR = PROJECT_ROOT / \"experiments\"\n",
    "EXPERIMENTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = EXPERIMENTS_DIR / \"full_pipeline_eval.json\"\n",
    "\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Saved evaluation results to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
